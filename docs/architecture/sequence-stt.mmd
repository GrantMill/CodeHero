sequenceDiagram
  participant User
  participant Browser as Browser (Blazor + JS, Continuous)
  participant Web as Web (CodeHero.Web)
  participant Speech as ISpeechService
  participant Foundry as Azure Foundry
  participant Whisper as stt-whisper (Docker)

  User->>Browser: Speak phrase (Continuous On)
  Browser->>Browser: VAD slices on silence, resample to16k WAV
  Browser->>Web: POST /api/stt (audio/wav)
  Web->>Speech: TranscribeAsync(wav)
  alt Foundry configured
    Speech->>Foundry: POST /openai/deployments/{gpt-4o-transcribe-diarize}/audio/transcriptions
    Foundry-->>Speech: { text }
  else Local Whisper configured
    Speech->>Whisper: POST /stt (multipart/form-data)
    Whisper-->>Speech: { text }
  else Not configured
    Speech-->>Web: "" (empty)
  end
  Speech-->>Web: transcription
  Web-->>Browser: text/plain
  Browser-->>User: show transcript (you: ...)

  Browser->>Web: POST /api/agent/chat (text)
  Web->>Agent: ChatAsync(text)
  Agent-->>Web: reply
  Web-->>Browser: reply
  Browser-->>User: show reply (agent: ...) and continue
